{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# File for training the gaze Estimator\n",
    "#Author: Srinivas Kumar R (srinivas1996kumar@gmail.com)\n",
    "\n",
    "# All the required imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "import h5py\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Since some of the imports might be in parent directory. \n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir) \n",
    "\n",
    "from models.gazeheadResnet import GazeHeadResNet\n",
    "import losses\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Required pre processing for feeding image to model.\n",
    "def preprocess_image(image):\n",
    "     ycrcb = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "     ycrcb[:, :, 0] = cv2.equalizeHist(ycrcb[:, :, 0])\n",
    "     image = cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2RGB)\n",
    "     image = np.transpose(image, [2, 0, 1])  # Colour image\n",
    "     image = 2.0 * image / 255.0 - 1\n",
    "     return image\n",
    "\n",
    "# Recovering image to write to a jpeg or png file. \n",
    "def recover_image(x):\n",
    "     x = (x + 1.0)*255.0/2.0\n",
    "     x = np.clip(x, 0, 255) # Avoiding parts which have over or under flowed\n",
    "     x = x.astype(np.uint0)\n",
    "     \n",
    "     x = np.transpose(x, [1, 2, 0]) # Channel, height and width to height width and channel\n",
    "\n",
    "     x = x[:, :, ::-1] # Convertin  RGB to BGR since openCV uses that\n",
    "\n",
    "     return x\n",
    "\n",
    "\n",
    "# Method for doing the predictions and if required the backward prop\n",
    "# during the training. \n",
    "def execute_step(model, X_numpy, labels_numpy, phase=\"train\"):\n",
    "\n",
    "    X_label = []\n",
    "    for i in range(len(X_numpy)):\n",
    "        X_label.append([X_numpy[i, :].astype(float), labels_numpy[i, :].astype(float)])\n",
    "\n",
    "    # Combine the X and y values into the dataloader. \n",
    "    dataloader = DataLoader(X_label, batch_size=128, shuffle=True)\n",
    "    \n",
    "    loss_list = []\n",
    "\n",
    "    for  input, label in dataloader:\n",
    "\n",
    "        # Set the model mode based on the phase. \n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "        elif phase == \"eval\":\n",
    "            model.eval()\n",
    "\n",
    "        # Backward prop only required for training phase. \n",
    "        with torch.set_grad_enabled(phase == \"train\"):\n",
    "\n",
    "            # Set teh gradients to 0 for each batch. \n",
    "            optimizer_ad.zero_grad()\n",
    "\n",
    "            # Do the prediction.\n",
    "            gaze_hat, head_hat = model(input.float().to(device))\n",
    "\n",
    "            # Angular Loss(Cosine similarity loss)\n",
    "            loss1 = criterion1(gaze_hat, label.to(device))\n",
    "            \n",
    "\n",
    "            #print(\"The estimated gazes are: \" + str(gaze_hat))\n",
    "            #print(\"The actual labels are: \" + str(label))\n",
    "                    \n",
    "            loss_list.extend(loss1.tolist())\n",
    "\n",
    "            if phase == \"train\":\n",
    "                # L1 loss this is required for accumulating gradients\n",
    "                loss2 = criterion( loss1, torch.zeros_like(loss1).to(device))\n",
    "                loss2.backward()\n",
    "\n",
    "                # Updating the weights \n",
    "                optimizer_ad.step()\n",
    "\n",
    "                # Decaying the learning rates\n",
    "                exp_lr_scheduler.step()\n",
    "\n",
    "            #print(\"The loss list is: \" + str(loss_list))\n",
    "    \n",
    "    return loss_list\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Initializing the model\n",
    "def init_model(from_path=None):\n",
    "\n",
    "\n",
    "     torch.cuda.empty_cache()\n",
    "\n",
    "     # Model to be trained\n",
    "     gaze_head_resnet = GazeHeadResNet()\n",
    "     gaze_head_resnet = nn.DataParallel(gaze_head_resnet)\n",
    "     gaze_head_resnet.to(\"cuda\")\n",
    "\n",
    "     # Criterion to minimize\n",
    "     # Angular loss , i.e cosine similarity\n",
    "     global criterion, criterion1\n",
    "     criterion1 = losses.gaze_angular_loss\n",
    "\n",
    "     # L1 loss for back prop\n",
    "     criterion = nn.L1Loss()\n",
    "\n",
    "     # Optimizer\n",
    "     global optimizer_ad\n",
    "     optimizer_ad = optim.Adam(gaze_head_resnet.parameters(), 0.0003, (0.9, 0.95))\n",
    "\n",
    "     # Scheduler for decaying the learning rate\n",
    "     global exp_lr_scheduler\n",
    "     exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ad, step_size=50000, gamma=0.1)\n",
    "\n",
    "\n",
    "     state_dict = {}\n",
    "     # Loading from a pre trained model \n",
    "     if not from_path is None:\n",
    "          checkpoint = torch.load(from_path)\n",
    "          for key in checkpoint.keys():\n",
    "               state_dict[\"module.\" + key] = checkpoint[key]\n",
    "\n",
    "          gaze_head_resnet.load_state_dict(checkpoint)\n",
    "\n",
    "     print(\"Done Initializing the model\")\n",
    "\n",
    "     return gaze_head_resnet"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#Method for going over the samples batch wise and training the model. \n",
    "def iterate_and_train_model(h5_path, model, num_epochs=4, num_img=10, data=\"aug\"):\n",
    "\n",
    "\n",
    "    # Dict for containing the random images chosen for a particular person, key is person id. \n",
    "    person_samples_dict = {}\n",
    "\n",
    "    mean_losses = []\n",
    "    total_imgs = 0\n",
    "    \n",
    "    #Iterating over the multiple epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        loss_list = []\n",
    "\n",
    "        # Since the group structures are different for normal and augmented datasets. \n",
    "        group_key = \"image\" if data == \"aug\" else \"pixels\"\n",
    "        # print(\"The data is : \" + str(data))\n",
    "        # print(\"The group key is \" + str(group_key))\n",
    "\n",
    "\n",
    "        with h5py.File(h5_path, 'r') as f:\n",
    "            # Counter for all of the images. \n",
    "            cnt = 0\n",
    "\n",
    "\n",
    "            for person_id, group in f.items():\n",
    "                #print(group[\"labels\"][0, :2])\n",
    "\n",
    "                # List for storing the y values\n",
    "                gaze_curr_list = []\n",
    "\n",
    "                # Choose 10 random images from for the group\n",
    "                if not person_id in person_samples_dict:\n",
    "                    rng = default_rng()\n",
    "                    len_pix = len(group[group_key])\n",
    "                    size = min(num_img, len_pix)\n",
    "                    person_samples_dict[person_id] = rng.choice(len(group[group_key]), size=size, replace=False)\n",
    "\n",
    "                numbers = person_samples_dict[person_id]\n",
    "                \n",
    "                # initing the X matrix \n",
    "                X_numpy = np.zeros((len(numbers), 3, 128, 128), dtype=np.float)\n",
    "\n",
    "                # Counter for images of a person\n",
    "                cnt1 = 0\n",
    "\n",
    "                for idx in numbers:\n",
    "\n",
    "                    if data == \"gc\":\n",
    "                        # Pre processing required for images of gaze capture\n",
    "                        eyes = preprocess_image(group[\"pixels\"][idx, :])\n",
    "                        gaze = group['labels'][idx, :2]\n",
    "                    else:\n",
    "                        # Augmented dataset images are already pre processed. \n",
    "                        eyes = group[\"image\"][idx][:]\n",
    "                        gaze = group[\"gaze\"][idx, :2]\n",
    "\n",
    "                    # if cnt < 10:\n",
    "                        # cv2.imwrite(\"/bigpool/fachpraktikum2021/group5/dir_srinivas/outputs_sted/recovered_\" + str(cnt) + \".png\", recover_image(eyes))\n",
    "\n",
    "                    # Filling in the X matrix. \n",
    "                    X_numpy[cnt1] = eyes.astype(np.double)\n",
    "                    cnt1 += 1\n",
    "\n",
    "                    # Filling in the y vector\n",
    "                    gaze_curr_list.append(gaze)\n",
    "\n",
    "                    cnt += 1\n",
    "                \n",
    "\n",
    "                # Splitting into training and development set. \n",
    "                # Note that we got best result by training on full set hence a value of 1.\n",
    "                train_size = int(1*(len(group[group_key])))\n",
    "                dev_size = len(group[group_key]) - train_size\n",
    "\n",
    "                \n",
    "                # Guard rail for not exceeding total training image count\n",
    "                if cnt >= num_img*1000:\n",
    "                    train_size = num_img*1000 - (cnt - len(group[group_key]))\n",
    "\n",
    "                X_train_numpy = X_numpy[:train_size,:]\n",
    "                X_eval_numpy = X_numpy[train_size:, :]\n",
    "\n",
    "                Y_train = gaze_curr_list[0:train_size]\n",
    "                Y_eval = gaze_curr_list[train_size:]\n",
    "\n",
    "                    \n",
    "                #print(\"The length of train is: \" + str(len(X_train_numpy)) )\n",
    "                #print(\"The length of eval is: \" + str(len(X_eval_numpy)) )\n",
    "\n",
    "                # Do the training \n",
    "                loss_list.extend(execute_step(model, X_train_numpy, np.array(Y_train), \"train\"))\n",
    "               \n",
    "                #loss_list.extend(execute_training_step(X_eval_numpy, np.array(Y_eval), \"eval\"))\n",
    "\n",
    "                \n",
    "                # Guard rail for not exceeding total training image count\n",
    "                if(cnt >= num_img*1000):\n",
    "                    break\n",
    "\n",
    "\n",
    "                # print(\"Finished processing : \" + str(cnt) )\n",
    "                # print(\"The length of the list is: \" + str(len(loss_list)))\n",
    "                # print(\"The mean loss is : \" + str(np.mean(loss_list)))\n",
    "\n",
    "\n",
    "        mean_losses.append(np.mean(loss_list))\n",
    "\n",
    "        total_imgs = len(loss_list)\n",
    "        print(\"The mean loss for \" + str(total_imgs) + \"k images,  after epoch: \" + str(epoch + 1) + \"is : \" + str(np.mean(loss_list)))\n",
    "\n",
    "        \n",
    "\n",
    "    print(\"Finished Computing the gaze\")\n",
    "    \n",
    "    \n",
    "    # Saving the trained model. \n",
    "    model_name = \"gaze_head_resnet_\" + data + \"_randimg_\" + str(num_img)  +  \"_epo_\" +str(num_epochs) + \"_.pt\"\n",
    "    torch.save(model.state_dict(), \n",
    "\"/bigpool/fachpraktikum2021/group5/dir_srinivas/STED-gaze/pre-trained/\" + model_name)\n",
    "\n",
    "    return model, mean_losses, total_imgs\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#Method for performing the predictions\n",
    "def test_model(h5_path, model, data=\"aug\"):\n",
    "\n",
    "    loss_list = []\n",
    "\n",
    "    with h5py.File(h5_path, 'r') as f:\n",
    "        # Counter for all of the images. \n",
    "        cnt = 0\n",
    "\n",
    "        for person_id, group in f.items():\n",
    "            \n",
    "            # List for storing the y values\n",
    "            gaze_curr_list = []\n",
    "\n",
    "            # Init the X matrix\n",
    "            X_numpy = np.zeros((len(group[\"pixels\"]), 3, 128, 128), dtype=np.float)\n",
    "\n",
    "            # Counter for images of a person\n",
    "            cnt1 = 0\n",
    "\n",
    "            for idx in range(len(group[\"pixels\"])):\n",
    "\n",
    "                if data == \"gc\":\n",
    "                    eyes = preprocess_image(group[\"pixels\"][idx, :])\n",
    "                    gaze = group['labels'][idx, :2]\n",
    "                else:\n",
    "                    eyes = group[\"image\"][idx][:]\n",
    "                    gaze = group[\"gaze\"][idx, :2]\n",
    "\n",
    "                # Filling in the X matrix\n",
    "                X_numpy[cnt1] = eyes.astype(np.double)\n",
    "                cnt1 += 1\n",
    "\n",
    "                # Filling in the y vector\n",
    "                gaze_curr_list.append(gaze)\n",
    "\n",
    "                cnt += 1\n",
    "             \n",
    "\n",
    "            # Perform the prediction.\n",
    "            loss_list.extend(execute_step(model, X_numpy, np.array(gaze_curr_list), \"test\"))\n",
    "            \n",
    "    print(\"Finished Computing the gaze\")\n",
    "    \n",
    "    \n",
    "    return loss_list\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Dict containing the trained models\n",
    "trained_models = {\n",
    "    \"aug\": [],\n",
    "    \"gc\": [] \n",
    "}\n",
    "\n",
    "# File containing augmented dataset.\n",
    "h5_path_red = \"/bigpool/fachpraktikum2021/group5/dir_srinivas/outputs_sted/Redirected_samples1.h5\"\n",
    "\n",
    "# File containing the processed subset of Gaze Capture. \n",
    "h5_path_gc = \"/bigpool/fachpraktikum2021/group5/dir_srinivas/outputs_sted/GazeCapture.h5\"\n",
    "\n",
    "#Number of images(in 1000's) to train on \n",
    "num_imgs = [1, 2, 5, 10, 20, 50]\n",
    "\n",
    "\n",
    "\n",
    "# Training on augmented/gazecapture dataset for different number images and 20 epochs each. \n",
    "for num_img in num_imgs:\n",
    "\n",
    "    for ds in [ \"gc\", \"aug\"]:\n",
    "    \n",
    "        if ds == \"gc\":\n",
    "            h5_path  = h5_path_gc\n",
    "        else:\n",
    "            h5_path = h5_path_red\n",
    "\n",
    "\n",
    "        model = init_model()\n",
    "        trained_model, mean_losses, total_imgs = iterate_and_train_model(h5_path, model, 20, num_img, ds)\n",
    "        trained_models[ds].append({num_img : {\"model\":trained_model, \"train_losses\": mean_losses, \"total_imgs\":total_imgs}})\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done Initializing the model\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-6-6cf3100a1c30>:38: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_numpy = np.zeros((len(numbers), 3, 128, 128), dtype=np.float)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The mean loss for 1000k images,  after epoch: 1is : 14.500081574844812\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 2is : 12.465527562918544\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 3is : 12.418579378807328\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 4is : 12.20887061558969\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 5is : 12.008155459116114\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 6is : 11.782931142662601\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 7is : 11.713594330358829\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 8is : 11.568904246178743\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 9is : 11.533698436693609\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 10is : 11.440738375833979\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 11is : 11.332737812881176\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 12is : 11.249009948278287\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 13is : 11.218353163560295\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 14is : 11.049356730927991\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 15is : 10.975045211671398\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 16is : 10.939842485245416\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 17is : 10.871666253981006\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 18is : 10.822038244565105\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 19is : 10.781913553233904\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 20is : 10.752532215429405\n",
      "Finished Computing the gaze\n",
      "Done Initializing the model\n",
      "The mean loss for 1000k images,  after epoch: 1is : 14.629292723823866\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 2is : 12.613936692496507\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 3is : 11.909362351811327\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 4is : 11.253851083419047\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 5is : 11.094072761641462\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 6is : 10.785476529638453\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 7is : 10.997948405840624\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 8is : 11.165801768564945\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 9is : 10.561737510097773\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 10is : 10.265259531129576\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 11is : 9.993979189253952\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 12is : 9.85728454682719\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 13is : 9.619571767010642\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 14is : 9.91518820198527\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 15is : 9.674980283723707\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 16is : 9.572864548155929\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 17is : 9.395944593119209\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 18is : 9.110945784006201\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 19is : 9.408624668490638\n",
      "Finished Computing the gaze\n",
      "The mean loss for 1000k images,  after epoch: 20is : 9.26305062635813\n",
      "Finished Computing the gaze\n",
      "Done Initializing the model\n",
      "The mean loss for 2001k images,  after epoch: 1is : 13.030989714614872\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2001k images,  after epoch: 2is : 10.961251889351656\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2001k images,  after epoch: 3is : 10.719217406139306\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2001k images,  after epoch: 4is : 10.489297014104269\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2001k images,  after epoch: 5is : 10.27949152580608\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2001k images,  after epoch: 6is : 10.118780293548994\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2001k images,  after epoch: 7is : 10.063437065889039\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2001k images,  after epoch: 8is : 9.900259247890109\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2001k images,  after epoch: 9is : 9.611082590064361\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2001k images,  after epoch: 10is : 9.398728436633826\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2001k images,  after epoch: 11is : 9.602513427558529\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2001k images,  after epoch: 12is : 9.417515826027161\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2001k images,  after epoch: 13is : 9.370986633192167\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2001k images,  after epoch: 14is : 9.100288939489692\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2001k images,  after epoch: 15is : 9.026126256097978\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2001k images,  after epoch: 16is : 8.86615650838571\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2001k images,  after epoch: 17is : 8.944756240758009\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2001k images,  after epoch: 18is : 8.735705523595025\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2001k images,  after epoch: 19is : 8.617839368862564\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2001k images,  after epoch: 20is : 8.56169906467048\n",
      "Finished Computing the gaze\n",
      "Done Initializing the model\n",
      "The mean loss for 2000k images,  after epoch: 1is : 12.840811756875002\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2000k images,  after epoch: 2is : 10.686372248408029\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2000k images,  after epoch: 3is : 10.360065936590404\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2000k images,  after epoch: 4is : 10.025030466487696\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2000k images,  after epoch: 5is : 9.804410100381467\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2000k images,  after epoch: 6is : 9.4717045607533\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2000k images,  after epoch: 7is : 9.38744518896125\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2000k images,  after epoch: 8is : 9.323213563851004\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2000k images,  after epoch: 9is : 9.19302705521062\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2000k images,  after epoch: 10is : 9.289799012351683\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2000k images,  after epoch: 11is : 9.409308764144779\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2000k images,  after epoch: 12is : 9.07934970514832\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2000k images,  after epoch: 13is : 9.10714983330887\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2000k images,  after epoch: 14is : 9.014605797994129\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2000k images,  after epoch: 15is : 8.918613586722222\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2000k images,  after epoch: 16is : 8.911877251142432\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2000k images,  after epoch: 17is : 8.77722224356186\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2000k images,  after epoch: 18is : 8.631054362290177\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2000k images,  after epoch: 19is : 8.673029220138478\n",
      "Finished Computing the gaze\n",
      "The mean loss for 2000k images,  after epoch: 20is : 8.459754320982999\n",
      "Finished Computing the gaze\n",
      "Done Initializing the model\n",
      "The mean loss for 5001k images,  after epoch: 1is : 10.994832032558364\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5001k images,  after epoch: 2is : 9.140747062941939\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5001k images,  after epoch: 3is : 9.028047554421702\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5001k images,  after epoch: 4is : 8.748694942672563\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5001k images,  after epoch: 5is : 8.333801748988972\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5001k images,  after epoch: 6is : 7.978806835284141\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5001k images,  after epoch: 7is : 7.111785530706145\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5001k images,  after epoch: 8is : 6.93048557096593\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5001k images,  after epoch: 9is : 6.555369936188625\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5001k images,  after epoch: 10is : 6.258110930022596\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5001k images,  after epoch: 11is : 5.993137993377373\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5001k images,  after epoch: 12is : 5.763362150207868\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5001k images,  after epoch: 13is : 5.427378215451966\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5001k images,  after epoch: 14is : 5.255281613615926\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5001k images,  after epoch: 15is : 4.9422097439357024\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5001k images,  after epoch: 16is : 4.840326456423647\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5001k images,  after epoch: 17is : 4.6704910031164415\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5001k images,  after epoch: 18is : 4.399403505713579\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5001k images,  after epoch: 19is : 4.200705267474428\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5001k images,  after epoch: 20is : 4.046019779291308\n",
      "Finished Computing the gaze\n",
      "Done Initializing the model\n",
      "The mean loss for 5002k images,  after epoch: 1is : 10.400501910882102\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5002k images,  after epoch: 2is : 7.894879108043633\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5002k images,  after epoch: 3is : 7.099960044519418\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5002k images,  after epoch: 4is : 6.418009691519588\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5002k images,  after epoch: 5is : 6.0200092306979816\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5002k images,  after epoch: 6is : 5.529837299033531\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5002k images,  after epoch: 7is : 5.300166905066448\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5002k images,  after epoch: 8is : 5.053326315924759\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5002k images,  after epoch: 9is : 4.79476794563836\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5002k images,  after epoch: 10is : 4.69907708872197\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5002k images,  after epoch: 11is : 4.484964208376934\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5002k images,  after epoch: 12is : 4.278233384448089\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5002k images,  after epoch: 13is : 4.017127292156923\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5002k images,  after epoch: 14is : 3.855247714705636\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5002k images,  after epoch: 15is : 3.7313720587091663\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5002k images,  after epoch: 16is : 3.6205237123625946\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5002k images,  after epoch: 17is : 3.6143434177375378\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5002k images,  after epoch: 18is : 3.31891889320925\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5002k images,  after epoch: 19is : 3.2504079669131216\n",
      "Finished Computing the gaze\n",
      "The mean loss for 5002k images,  after epoch: 20is : 3.140363498593402\n",
      "Finished Computing the gaze\n",
      "Done Initializing the model\n",
      "The mean loss for 10006k images,  after epoch: 1is : 9.434711201162605\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10006k images,  after epoch: 2is : 7.1433782557657235\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10006k images,  after epoch: 3is : 6.468392659268882\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10006k images,  after epoch: 4is : 5.984445175844182\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10006k images,  after epoch: 5is : 5.6868316204629314\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10006k images,  after epoch: 6is : 5.437437047481723\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10006k images,  after epoch: 7is : 5.2502628700375675\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10006k images,  after epoch: 8is : 5.111430766572714\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10006k images,  after epoch: 9is : 4.9748072635340534\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10006k images,  after epoch: 10is : 4.616890164815653\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10006k images,  after epoch: 11is : 4.7072906585569\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10006k images,  after epoch: 12is : 4.277626097210674\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10006k images,  after epoch: 13is : 4.189654308008541\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10006k images,  after epoch: 14is : 4.038459291763695\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10006k images,  after epoch: 15is : 3.906818690784724\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10006k images,  after epoch: 16is : 3.67892446035781\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10006k images,  after epoch: 17is : 3.6018667421627115\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10006k images,  after epoch: 18is : 3.3637485278202406\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10006k images,  after epoch: 19is : 3.3401089966442514\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10006k images,  after epoch: 20is : 3.0298144134406444\n",
      "Finished Computing the gaze\n",
      "Done Initializing the model\n",
      "The mean loss for 10000k images,  after epoch: 1is : 8.285484403370885\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10000k images,  after epoch: 2is : 6.188139407397684\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10000k images,  after epoch: 3is : 5.487019618006892\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10000k images,  after epoch: 4is : 5.023367066753836\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10000k images,  after epoch: 5is : 4.799231533145594\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10000k images,  after epoch: 6is : 4.532270692234851\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10000k images,  after epoch: 7is : 4.173650130685419\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10000k images,  after epoch: 8is : 3.877082435988645\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10000k images,  after epoch: 9is : 3.846791175445448\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10000k images,  after epoch: 10is : 3.6385405894241885\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10000k images,  after epoch: 11is : 3.3819739707577092\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10000k images,  after epoch: 12is : 3.411193545050286\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10000k images,  after epoch: 13is : 3.1598889437292406\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10000k images,  after epoch: 14is : 3.0825623687100476\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10000k images,  after epoch: 15is : 2.842235927905189\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10000k images,  after epoch: 16is : 2.70873871686626\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10000k images,  after epoch: 17is : 2.654106497121066\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10000k images,  after epoch: 18is : 2.613311023275199\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10000k images,  after epoch: 19is : 2.469003852733486\n",
      "Finished Computing the gaze\n",
      "The mean loss for 10000k images,  after epoch: 20is : 2.4341153489800504\n",
      "Finished Computing the gaze\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "aug_test_losses = []\n",
    "gc_test_losses = []\n",
    "\n",
    "# File containing the process MPIIGaze dataset, this is the testing set. \n",
    "h5_path_mpii = \"/bigpool/fachpraktikum2021/group5/dir_srinivas/outputs_sted/MPIIGaze.h5\"\n",
    "\n",
    "# This is for loading the pre trained models and testing them. \n",
    "\n",
    "# trained_models[\"aug\"].append({1: {\"model\": init_model(\"/bigpool/fachpraktikum2021/group5/dir_srinivas/STED-gaze/pre-trained/gaze_head_resnet_aug_randimg_1_epo_20_.pt\")}})\n",
    "# trained_models[\"aug\"].append({2: {\"model\": init_model(\"/bigpool/fachpraktikum2021/group5/dir_srinivas/STED-gaze/pre-trained/gaze_head_resnet_aug_randimg_2_epo_20_.pt\")}})\n",
    "# trained_models[\"aug\"].append({5: {\"model\": init_model(\"/bigpool/fachpraktikum2021/group5/dir_srinivas/STED-gaze/pre-trained/gaze_head_resnet_aug_randimg_5_epo_20_.pt\")}})\n",
    "# trained_models[\"aug\"].append({10: {\"model\": init_model(\"/bigpool/fachpraktikum2021/group5/dir_srinivas/STED-gaze/pre-trained/gaze_head_resnet_aug_randimg_10_epo_20_.pt\")}})\n",
    "# trained_models[\"aug\"].append({20: {\"model\": init_model(\"/bigpool/fachpraktikum2021/group5/dir_srinivas/STED-gaze/pre-trained/gaze_head_resnet_aug_randimg_20_epo_20_.pt\")}})\n",
    "# trained_models[\"aug\"].append({50: {\"model\": init_model(\"/bigpool/fachpraktikum2021/group5/dir_srinivas/STED-gaze/pre-trained/gaze_head_resnet_aug_randimg_50_epo_20_.pt\")}})\n",
    "\n",
    "\n",
    "# trained_models[\"gc\"].append({1: {\"model\": init_model(\"/bigpool/fachpraktikum2021/group5/dir_srinivas/STED-gaze/pre-trained/gaze_head_resnet_gc_randimg_1_epo_20_.pt\")}})\n",
    "# trained_models[\"gc\"].append({2: {\"model\": init_model(\"/bigpool/fachpraktikum2021/group5/dir_srinivas/STED-gaze/pre-trained/gaze_head_resnet_gc_randimg_2_epo_20_.pt\")}})\n",
    "# trained_models[\"gc\"].append({5: {\"model\": init_model(\"/bigpool/fachpraktikum2021/group5/dir_srinivas/STED-gaze/pre-trained/gaze_head_resnet_gc_randimg_5_epo_20_.pt\")}})\n",
    "# trained_models[\"gc\"].append({10: {\"model\": init_model(\"/bigpool/fachpraktikum2021/group5/dir_srinivas/STED-gaze/pre-trained/gaze_head_resnet_gc_randimg_10_epo_20_.pt\")}})\n",
    "# trained_models[\"gc\"].append({20: {\"model\": init_model(\"/bigpool/fachpraktikum2021/group5/dir_srinivas/STED-gaze/pre-trained/gaze_head_resnet_gc_randimg_20_epo_20_.pt\")}})\n",
    "# trained_models[\"gc\"].append({50: {\"model\": init_model(\"/bigpool/fachpraktikum2021/group5/dir_srinivas/STED-gaze/pre-trained/gaze_head_resnet_gc_randimg_50_epo_20_.pt\")}})\n",
    "\n",
    "#Performing  predictions on the MPII Gaze Dataset using the trained models\n",
    "for ds in [\"aug\", \"gc\"]:\n",
    "    for n_model in trained_models[ds]:\n",
    "        \n",
    "        key1 = list(n_model)[0]\n",
    "        model = n_model[key1][\"model\"]\n",
    "        if ds == \"aug\":\n",
    "            aug_test_losses.append(np.mean(test_model(h5_path_mpii, model, \"gc\")))\n",
    "        else:\n",
    "            gc_test_losses.append(np.mean(test_model(h5_path_mpii, model, \"gc\")))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(aug_test_losses)\n",
    "print(gc_test_losses)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Plotting the training losses\n",
    "\n",
    "training_losses = trained_models[\"aug\"][0][1][\"train_losses\"]\n",
    "epochs = [epoch for epoch in range(len(training_losses))]\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(tight_layout=True)\n",
    "\n",
    "p1,  = ax.plot(epochs, training_losses,  color='blue', marker='o', label='Angular loss')\n",
    "\n",
    "ax.set_title(\"Training loss vs Epochs (for 1000 images)\")\n",
    "ax.set_xlabel(\"Epoch Count\")\n",
    "ax.set_ylabel(\"Training Angular Loss in degrees\")\n",
    "\n",
    "ax.legend(handles=[p1], title='Legend', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "ax.grid(True)\n",
    "fig.savefig('/bigpool/fachpraktikum2021/group5/dir_srinivas/STED-gaze/Gaze_Estimation/plots/' + 'training_loss.jpg',\n",
    "            )\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plotting the mean loss for normal and augmented dataset for different \n",
    "# number of images trained on. \n",
    "image_numbers = [1000, 2000, 5000, 10000, 20000, 50000]\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(tight_layout=True)\n",
    "\n",
    "p1,  = ax.plot(image_numbers, aug_test_losses, color='blue', marker='o', label='Augmented dataset')\n",
    "p2,  = ax.plot(image_numbers, gc_test_losses, color='red', marker='o', label='Normal dataset')\n",
    "\n",
    "\n",
    "\n",
    "ax.set_title(\"Gaze Estimation Loss for MPIIGaze Dataset\")\n",
    "ax.set_xlabel(\"Number of images trained on\")\n",
    "ax.set_ylabel(\"Mean Estimation loss in degrees\")\n",
    "\n",
    "ax.legend(handles=[p1, p2], title='Legend', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "ax.grid(True)\n",
    "fig.savefig('/bigpool/fachpraktikum2021/group5/dir_srinivas/STED-gaze/Gaze_Estimation/plots/' + 'augvsnorm_comparison.jpg',\n",
    "            )\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0a7e8266d4960bf55ec4202778d20d6fb4fd9d14c12b2b3e2041a81f30d16324"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('venv38': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}