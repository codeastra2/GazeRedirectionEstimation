{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir) \n",
    "\n",
    "\n",
    "import h5py\n",
    "import cv2\n",
    "import numpy as np\n",
    "from models.gazeheadResnet import GazeHeadResNet\n",
    "import losses\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from numpy.random import default_rng\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def preprocess_image(image):\n",
    "     ycrcb = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "     ycrcb[:, :, 0] = cv2.equalizeHist(ycrcb[:, :, 0])\n",
    "     image = cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2RGB)\n",
    "     image = np.transpose(image, [2, 0, 1])  # Colour image\n",
    "     image = 2.0 * image / 255.0 - 1\n",
    "     return image\n",
    "\n",
    "def recover_image(x):\n",
    "     x = (x + 1.0)*255.0/2.0\n",
    "     x = np.clip(x, 0, 255) # Avoiding parts which have over or under flowed\n",
    "     x = x.astype(np.uint0)\n",
    "     \n",
    "     x = np.transpose(x, [1, 2, 0]) # Channel, height and width to height width and channel\n",
    "\n",
    "     x = x[:, :, ::-1] # Convertin  RGB to BGR since openCV uses that\n",
    "\n",
    "     return x\n",
    "\n",
    "\n",
    "def execute_step(model, X_numpy, labels_numpy, phase=\"train\"):\n",
    "\n",
    "    X_label = []\n",
    "    for i in range(len(X_numpy)):\n",
    "        X_label.append([X_numpy[i, :].astype(float), labels_numpy[i, :].astype(float)])\n",
    "\n",
    "    dataloader = DataLoader(X_label, batch_size=128, shuffle=True)\n",
    "    \n",
    "    loss_list = []\n",
    "\n",
    "    for  input, label in dataloader:\n",
    "\n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "        elif phase == \"eval\":\n",
    "            model.eval()\n",
    "\n",
    "        with torch.set_grad_enabled(phase == \"train\"):\n",
    "\n",
    "            optimizer_ad.zero_grad()\n",
    "\n",
    "            gaze_hat, head_hat = model(input.float().to(device))\n",
    "            loss1 = criterion1(gaze_hat, label.to(device))\n",
    "            \n",
    "\n",
    "            #print(\"The estimated gaes are: \" + str(gaze_hat))\n",
    "\n",
    "            #print(\"The predicted labels are: \" + str(label))\n",
    "                    \n",
    "            loss_list.extend(loss1.tolist())\n",
    "\n",
    "            if phase == \"train\":\n",
    "                loss2 = criterion( loss1, torch.zeros_like(loss1).to(device))\n",
    "                loss2.backward()\n",
    "\n",
    "                optimizer_ad.step()\n",
    "\n",
    "                exp_lr_scheduler.step()\n",
    "\n",
    "            #print(\"THe loss list is: \" + str(loss_list))\n",
    "    \n",
    "    return loss_list\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "\n",
    "\n",
    "     torch.cuda.empty_cache()\n",
    "\n",
    "     #Model to be trained\n",
    "     gaze_head_resnet = GazeHeadResNet()\n",
    "     gaze_head_resnet = nn.DataParallel(gaze_head_resnet)\n",
    "     gaze_head_resnet.to(\"cuda\")\n",
    "\n",
    "     #Criterion to minimize\n",
    "     global criterion, criterion1\n",
    "     criterion1 = losses.gaze_angular_loss\n",
    "     criterion = nn.L1Loss()\n",
    "\n",
    "     #Optimizer\n",
    "     global optimizer_ad\n",
    "     optimizer_ft = optim.SGD(gaze_head_resnet.parameters(), lr=0.8)\n",
    "\n",
    "     optimizer_ad = optim.Adam(gaze_head_resnet.parameters(), 0.0003, (0.9, 0.95))\n",
    "\n",
    "     global exp_lr_scheduler\n",
    "     exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ad, step_size=50000, gamma=0.1)\n",
    "\n",
    "\n",
    "     state_dict = {}\n",
    "     checkpoint = torch.load('/bigpool/fachpraktikum2021/group5/dir_srinivas/STED-gaze/pre-trained/gaze_head_resnet_aug_rand10000_epo48_.pt')\n",
    "     for key in checkpoint.keys():\n",
    "          state_dict[\"module.\" + key] = checkpoint[key]\n",
    "\n",
    "     #gaze_head_resnet.load_state_dict(checkpoint)\n",
    "\n",
    "     print(\"Done Initializing the model\")\n",
    "\n",
    "     return gaze_head_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_and_train_model(h5_path, model, num_epochs=4, num_img=10, data=\"aug\"):\n",
    "\n",
    "\n",
    "    person_samples_dict = {}\n",
    "    mean_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        #Cell for Iterating over the HDF5 file and training the data\n",
    "\n",
    "        loss_list = []\n",
    "        gaze_list = []\n",
    "\n",
    "        group_key = \"image\" if data == \"aug\" else \"pixels\"\n",
    "        # print(\"The data is : \" + str(data))\n",
    "        # print(\"The group key is \" + str(group_key))\n",
    "\n",
    "        with h5py.File(h5_path, 'r') as f:\n",
    "            cnt = 0\n",
    "\n",
    "    \n",
    "    \n",
    "            for person_id, group in f.items():\n",
    "                #print(group[\"labels\"][0, :2])\n",
    "\n",
    "        \n",
    "                gaze_curr_list = []\n",
    "                #gaze_list.extend(group[\"gaze\"][:].tolist())\n",
    "\n",
    "                #Choose 10 random images from for the group\n",
    "                if not person_id in person_samples_dict:\n",
    "                    rng = default_rng()\n",
    "                    len_pix = len(group[group_key])\n",
    "                    size = min(num_img, len_pix)\n",
    "                    person_samples_dict[person_id] = rng.choice(len(group[group_key]), size=size, replace=False)\n",
    "\n",
    "                numbers = person_samples_dict[person_id]\n",
    "                X_numpy = np.zeros((len(numbers), 3, 128, 128), dtype=np.float)\n",
    "\n",
    "\n",
    "                cnt1 = 0\n",
    "\n",
    "                for idx in numbers:\n",
    "\n",
    "                    if data == \"gc\":\n",
    "                        eyes = preprocess_image(group[\"pixels\"][idx, :])\n",
    "                        gaze = group['labels'][idx, :2]\n",
    "                    else:\n",
    "                        eyes = group[\"image\"][idx][:]\n",
    "                        gaze = group[\"gaze\"][idx, :2]\n",
    "\n",
    "                    # if cnt < 10:\n",
    "                        # cv2.imwrite(\"/bigpool/fachpraktikum2021/group5/dir_srinivas/outputs_sted/recovered_\" + str(cnt) + \".png\", recover_image(eyes))\n",
    "\n",
    "                    X_numpy[cnt1] = eyes.astype(np.double)\n",
    "                    cnt1 += 1\n",
    "\n",
    "                    gaze_list.append(gaze)\n",
    "                    gaze_curr_list.append(gaze)\n",
    "\n",
    "                    cnt += 1\n",
    "                    # if (cnt >= num_img):\n",
    "                        # break\n",
    "\n",
    "                \n",
    "                train_size = int(1*(len(group[group_key])))\n",
    "                dev_size = len(group[group_key]) - train_size\n",
    "                \n",
    "                X_train_numpy = X_numpy[:train_size,:]\n",
    "                X_eval_numpy = X_numpy[train_size:, :]\n",
    "\n",
    "                Y_train = gaze_curr_list[0:train_size]\n",
    "                Y_eval = gaze_curr_list[train_size:]\n",
    "\n",
    "                \n",
    "                #print(\"The length of train is: \" + str(len(X_train_numpy)) )\n",
    "                #print(\"The length of eval is: \" + str(len(X_eval_numpy)) )\n",
    "\n",
    "                loss_list.extend(execute_step(model, X_train_numpy, np.array(Y_train), \"train\"))\n",
    "                #loss_list.extend(execute_training_step(X_eval_numpy, np.array(Y_eval), \"eval\"))\n",
    "\n",
    "\n",
    "                # if(cnt >= num_img):\n",
    "                    # break\n",
    "\n",
    "\n",
    "                '''print(\"Finished processing : \" + str(cnt) )\n",
    "                print(\"The length of the list is: \" + str(len(loss_list)))\n",
    "                print(\"The mean loss is : \" + str(np.mean(loss_list)))'''\n",
    "\n",
    "        mean_losses.append(np.mean(loss_list))\n",
    "        print(\"The mean loss for \" + str(len(loss_list)) + \"k images,  after epoch: \" + str(epoch + 1) + \"is : \" + str(np.mean(loss_list)))\n",
    "\n",
    "        \n",
    "\n",
    "        #loss_list = perform_prediction(X_numpy, np.array(gaze_list))\n",
    "        print(\"Finished Computing the gaze\")\n",
    "    \n",
    "    \n",
    "    model_name = \"gaze_head_resnet_\" + data + \"_randimg_\" + str(num_img)  +  \"_epo_\" +str(num_epochs) + \"_.pt\"\n",
    "    torch.save(model.state_dict(), \n",
    "\"/bigpool/fachpraktikum2021/group5/dir_srinivas/STED-gaze/pre-trained/\" + model_name)\n",
    "    return model, mean_losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(h5_path, model, data=\"aug\"):\n",
    "\n",
    "    loss_list = []\n",
    "    gaze_list = []\n",
    "\n",
    "    group_key = \"image\" if data == \"aug\" else \"pixels\"\n",
    "    # print(\"The data is : \" + str(data))\n",
    "    # print(\"The group key is \" + str(group_key))\n",
    "\n",
    "    with h5py.File(h5_path, 'r') as f:\n",
    "        cnt = 0\n",
    "\n",
    "        for person_id, group in f.items():\n",
    "            #print(group[\"labels\"][0, :2])\n",
    "\n",
    "        \n",
    "            gaze_curr_list = []\n",
    "            #gaze_list.extend(group[\"gaze\"][:].tolist())\n",
    "\n",
    "            X_numpy = np.zeros((len(group[\"pixels\"]), 3, 128, 128), dtype=np.float)\n",
    "\n",
    "\n",
    "            cnt1 = 0\n",
    "\n",
    "            for idx in range(len(group[\"pixels\"])):\n",
    "\n",
    "                if data == \"gc\":\n",
    "                    eyes = preprocess_image(group[\"pixels\"][idx, :])\n",
    "                    gaze = group['labels'][idx, :2]\n",
    "                else:\n",
    "                    eyes = group[\"image\"][idx][:]\n",
    "                    gaze = group[\"gaze\"][idx, :2]\n",
    "\n",
    "                # if cnt < 10:\n",
    "                    # cv2.imwrite(\"/bigpool/fachpraktikum2021/group5/dir_srinivas/outputs_sted/recovered_\" + str(cnt) + \".png\", recover_image(eyes))\n",
    "\n",
    "                X_numpy[cnt1] = eyes.astype(np.double)\n",
    "                cnt1 += 1\n",
    "\n",
    "                gaze_list.append(gaze)\n",
    "                gaze_curr_list.append(gaze)\n",
    "\n",
    "                cnt += 1\n",
    "                # if (cnt >= num_img):\n",
    "                    # break\n",
    "\n",
    "            loss_list.extend(execute_step(model, X_numpy, np.array(gaze_curr_list), \"test\"))\n",
    "            #loss_list.extend(execute_training_step(X_eval_numpy, np.array(Y_eval), \"eval\"))\n",
    "\n",
    "\n",
    "            # if(cnt >= num_img):\n",
    "                 # break\n",
    "\n",
    "\n",
    "            '''print(\"Finished processing : \" + str(cnt) )\n",
    "            print(\"The length of the list is: \" + str(len(loss_list)))\n",
    "            print(\"The mean loss is : \" + str(np.mean(loss_list)))'''\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    #loss_list = perform_prediction(X_numpy, np.array(gaze_list))\n",
    "    print(\"Finished Computing the gaze\")\n",
    "    \n",
    "    \n",
    "    return loss_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Initializing the model\n",
      "The data is : gc\n",
      "The group key is pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-eb87a6d61037>:37: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_numpy = np.zeros((len(numbers), 3, 128, 128), dtype=np.float)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#iterate_and_train_model(1, 1001)\n",
    "\n",
    "trained_models = {\n",
    "    \"aug\": [],\n",
    "    \"gc\": [] \n",
    "}\n",
    "\n",
    "h5_path_red = \"/bigpool/fachpraktikum2021/group5/dir_srinivas/outputs_sted/Redirected_samples1.h5\"\n",
    "h5_path_gc = \"/bigpool/fachpraktikum2021/group5/dir_srinivas/outputs_sted/GazeCapture.h5\"\n",
    "\n",
    "\n",
    "num_imgs = [1, 2, 5, 10, 20, 50]\n",
    "\n",
    "for ds in [\"gc\", \"aug\"]:\n",
    "    \n",
    "    if ds == \"gc\":\n",
    "        h5_path  = h5_path_gc\n",
    "    else:\n",
    "        h5_path = h5_path_red\n",
    "        \n",
    "    for num_img in num_imgs:\n",
    "\n",
    "        model = init_model()\n",
    "        trained_model, mean_losses = iterate_and_train_model(h5_path, model, 20, num_img, ds)\n",
    "        trained_models[ds].append({num_img : {\"model\":trained_model, \"train_losses\": mean_losses}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_test_losses = []\n",
    "gc_test_losses = []\n",
    "h5_path_mpii = \"/bigpool/fachpraktikum2021/group5/dir_srinivas/outputs_sted/MPIIGaze.h5\"\n",
    "\n",
    "#print(type((trained_models[\"gc\"][0]).keys()))\n",
    "for ds in [\"aug\", \"gc\"]:\n",
    "    for n_model in trained_models[ds]:\n",
    "        #print(n_model_list)\n",
    "        for num_img in n_model:\n",
    "            \n",
    "            model = n_model[num_img][\"model\"]\n",
    "            if ds == \"aug\":\n",
    "                aug_test_losses.append(np.mean(test_model(h5_path_mpii, model, \"gc\")))\n",
    "            else:\n",
    "                gc_test_losses.append(np.mean(test_model(h5_path_mpii, model, \"gc\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1,  = plt.plot(num_imgs, aug_test_losses, color='blue', marker='o', label='Augmented dataset')\n",
    "p2,  = plt.plot(num_imgs, gc_test_losses, color='red', marker='o', label='Normal dataset')\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Gaze Estimation Loss for MPIIGaze Dataset\")\n",
    "plt.xlabel(\"Number of images trained on in thousands\")\n",
    "plt.ylabel(\"Mean Estimation loss in degrees\")\n",
    "\n",
    "plt.legend(handles=[p1, p2], title='Legend', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0a7e8266d4960bf55ec4202778d20d6fb4fd9d14c12b2b3e2041a81f30d16324"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('venv38': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}